{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\tejas\\Github projects\\RL - Mental health project\\pytorch_env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached gym-0.26.2-py3-none-any.whl\n",
      "Collecting gym_notices>=0.0.4\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Collecting cloudpickle>=1.2.0\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Collecting numpy>=1.18.0\n",
      "  Downloading numpy-2.2.4-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Installing collected packages: numpy, gym-notices, cloudpickle, gym\n",
      "Successfully installed cloudpickle-3.1.1 gym-0.26.2 gym-notices-0.0.8 numpy-2.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in c:\\users\\tejas\\github projects\\rl - mental health project\\pytorch_env\\lib\\site-packages (from stable-baselines3[extra]) (2.2.4)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\tejas\\github projects\\rl - mental health project\\pytorch_env\\lib\\site-packages (from stable-baselines3[extra]) (3.1.1)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "Collecting torch<3.0,>=2.3\n",
      "  Using cached torch-2.6.0-cp310-cp310-win_amd64.whl (204.2 MB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "Collecting gymnasium<1.2.0,>=0.29.1\n",
      "  Downloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\tejas\\github projects\\rl - mental health project\\pytorch_env\\lib\\site-packages (from stable-baselines3[extra]) (7.0.0)\n",
      "Collecting pygame\n",
      "  Downloading pygame-2.6.1-cp310-cp310-win_amd64.whl (10.6 MB)\n",
      "Collecting tensorboard>=2.9.1\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting pillow\n",
      "  Using cached pillow-11.1.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "Collecting rich\n",
      "  Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Collecting ale-py>=0.9.0\n",
      "  Downloading ale_py-0.10.2-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\tejas\\github projects\\rl - mental health project\\pytorch_env\\lib\\site-packages (from ale-py>=0.9.0->stable-baselines3[extra]) (4.13.1)\n",
      "Collecting farama-notifications>=0.0.1\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.71.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6\n",
      "  Downloading protobuf-6.30.2-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\tejas\\github projects\\rl - mental health project\\pytorch_env\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\tejas\\github projects\\rl - mental health project\\pytorch_env\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\tejas\\github projects\\rl - mental health project\\pytorch_env\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (57.4.0)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Collecting sympy==1.13.1\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-win_amd64.whl (218 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.57.0-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\tejas\\github projects\\rl - mental health project\\pytorch_env\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-win_amd64.whl (71 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tejas\\github projects\\rl - mental health project\\pytorch_env\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.19.1)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\tejas\\github projects\\rl - mental health project\\pytorch_env\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n",
      "Installing collected packages: mpmath, MarkupSafe, tzdata, sympy, pytz, pyparsing, pillow, networkx, mdurl, kiwisolver, jinja2, fsspec, fonttools, filelock, farama-notifications, cycler, contourpy, werkzeug, torch, tensorboard-data-server, protobuf, pandas, matplotlib, markdown-it-py, markdown, gymnasium, grpcio, absl-py, tqdm, tensorboard, stable-baselines3, rich, pygame, opencv-python, ale-py\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.2.2 ale-py-0.10.2 contourpy-1.3.1 cycler-0.12.1 farama-notifications-0.0.4 filelock-3.18.0 fonttools-4.57.0 fsspec-2025.3.2 grpcio-1.71.0 gymnasium-1.1.1 jinja2-3.1.6 kiwisolver-1.4.8 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.10.1 mdurl-0.1.2 mpmath-1.3.0 networkx-3.4.2 opencv-python-4.11.0.86 pandas-2.2.3 pillow-11.1.0 protobuf-6.30.2 pygame-2.6.1 pyparsing-3.2.3 pytz-2025.2 rich-14.0.0 stable-baselines3-2.6.0 sympy-1.13.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 torch-2.6.0 tqdm-4.67.1 tzdata-2025.2 werkzeug-3.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\tejas\\Github projects\\RL - Mental health project\\pytorch_env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shimmyNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: gymnasium in c:\\users\\tejas\\github projects\\rl - mental health project\\pytorch_env\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\tejas\\github projects\\rl - mental health project\\pytorch_env\\lib\\site-packages (from shimmy) (2.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\tejas\\github projects\\rl - mental health project\\pytorch_env\\lib\\site-packages (from gymnasium) (4.13.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\tejas\\github projects\\rl - mental health project\\pytorch_env\\lib\\site-packages (from gymnasium) (3.1.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\tejas\\github projects\\rl - mental health project\\pytorch_env\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Installing collected packages: shimmy\n",
      "Successfully installed shimmy-2.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\tejas\\Github projects\\RL - Mental health project\\pytorch_env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade shimmy gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from gym import spaces\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Mental_Health_Score_Dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotional_Score</th>\n",
       "      <th>Social_Media_Time_Score</th>\n",
       "      <th>Platform_Score</th>\n",
       "      <th>Usage_Pattern_Score</th>\n",
       "      <th>Impact_Score</th>\n",
       "      <th>Additional_Feature_Score</th>\n",
       "      <th>TFIDF_Score</th>\n",
       "      <th>Mental_Health_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>61</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotional_Score  Social_Media_Time_Score  Platform_Score  \\\n",
       "0               84                       13              20   \n",
       "1               56                       13              10   \n",
       "2               97                       23              19   \n",
       "3              114                       13              19   \n",
       "4               87                       13              19   \n",
       "\n",
       "   Usage_Pattern_Score  Impact_Score  Additional_Feature_Score  TFIDF_Score  \\\n",
       "0                   18            27                        38            0   \n",
       "1                    2             0                        35            0   \n",
       "2                   18            61                        34            0   \n",
       "3                   11            54                        63            0   \n",
       "4                   18            25                        10            0   \n",
       "\n",
       "   Mental_Health_Score  \n",
       "0                  200  \n",
       "1                  116  \n",
       "2                  252  \n",
       "3                  274  \n",
       "4                  172  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MentalHealthEnv(gym.Env):\n",
    "    def __init__(self, df):\n",
    "        super(MentalHealthEnv, self).__init__()\n",
    "\n",
    "        #loading the dataset\n",
    "        self.df = df.copy()\n",
    "        self.current_index = 0\n",
    "\n",
    "\n",
    "        #define state: 7 mental health scores (ranging between 0 to 300)\n",
    "        self.observation_space = spaces.Box(low = 0, high = 300, shape = (7,), dtype = np.float32)\n",
    "\n",
    "        # defining action space\n",
    "        self.actions = [\n",
    "            \"Engage in Outdoor activities\",\n",
    "            \"Reduce the social media usage\",\n",
    "            \"Watch educational videos\",\n",
    "            \"Increase mindfulness practicess like yoga\",\n",
    "            \"Interact with positive communities\",\n",
    "            \"Avoid stress-inducing content\",\n",
    "            \"Follow a structured daily routine\"\n",
    "        ]\n",
    "\n",
    "        self.action_space = spaces.Discrete(len(self.actions))\n",
    "\n",
    "        #initiating state: random values between 50 and 250 (to avoid zero-starting issues)\n",
    "        self.state = np.random.uniform(low = 50, high = 250, size = (7,))\n",
    "\n",
    "        # define action effects (each action affects specific scores)\n",
    "        self.action_effects = {\n",
    "            \"Engage in Outdoor activities\": np.array([10, 5, 0, 8, -5, 7, 0]),\n",
    "            \"Reduce the social media usage\": np.array([5, -15, 0, 0, 10, 0, 0]),\n",
    "            \"Watch educational videos\": np.array([5, 0, 15, 7, -3, 10, 0]),\n",
    "            \"Increase mindfulness practicess like yoga\": np.array([12, 0, 0, 5, -8, 15, 0]),\n",
    "            \"Interact with positive communities\": np.array([6, 0, -8, 0, 12, 0, 0]),\n",
    "            \"Avoid stress-inducing content\": np.array([6, 0, -8, 0, 12, 0, 0]),\n",
    "            \"Follow a structured daily routine\": np.array([10, 0, 0, 0, 7, 8, 0])\n",
    "        }\n",
    "        self.state = self.get_state_from_df()\n",
    "\n",
    "\n",
    "    def get_state_from_df(self):\n",
    "        # extract the initial state from the dataframe based on the current index\n",
    "        row = self.df.iloc[self.current_index]\n",
    "        return np.array(row[:-1])\n",
    "    \n",
    "    def step(self, action):\n",
    "        #apply an action and update mental health scores\n",
    "        self.state = np.clip(self.state + self.action_effects[self.actions[action]], 0, 300)\n",
    "\n",
    "\n",
    "        # reward: Improvement in mental health score \n",
    "        self.df.at[self.current_index, \"Mental_Health_Score\"] = np.sum(self.state)\n",
    "        reward = self.df.at[self.current_index, \"Mental_Health_Score\"]\n",
    "\n",
    "        #print(f\"State Shape: {self.state.shape}\")\n",
    "\n",
    "        done = np.all(self.state >= 280) #stops if all the score are near 300\n",
    "        \n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Move to the next user in the dataset or restart if finished.\"\"\"\n",
    "        self.current_index += 1  # Move to the next row\n",
    "        if self.current_index >= len(self.df):\n",
    "            self.current_index = 0  # Reset if all users are processed\n",
    "        self.state = self.get_state_from_df()\n",
    "        return self.state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MentalHealthEnv(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN, A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tejas\\Github projects\\RL - Mental health project\\pytorch_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.73    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 94.9     |\n",
      "|    value_loss         | 5.35e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.56    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 81.5     |\n",
      "|    value_loss         | 5.19e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 354      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 75       |\n",
      "|    value_loss         | 8.42e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 359       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.33     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 153       |\n",
      "|    value_loss         | 4.63e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 346      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.88    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 104      |\n",
      "|    value_loss         | 7.44e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.968   |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 78.5     |\n",
      "|    value_loss         | 9e+03    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.84    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 29.9     |\n",
      "|    value_loss         | 1.2e+04  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.692   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 20.7     |\n",
      "|    value_loss         | 1.2e+04  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 349       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.523    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 14.3      |\n",
      "|    value_loss         | 1.19e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.238   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 4.94     |\n",
      "|    value_loss         | 1.19e+04 |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dqn_model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "dqn_model.learn(total_timesteps=5000)\n",
    "dqn_model.save(\"mental_health_dqn_model\")\n",
    "\n",
    "# Train A2C\n",
    "a2c_model = A2C(\"MlpPolicy\", env, verbose=1)\n",
    "a2c_model.learn(total_timesteps=5000)\n",
    "a2c_model.save(\"mental_health_a2c_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, env, num_episodes=len(df), max_steps=1):\n",
    "    total_rewards = []\n",
    "    action_counts = np.zeros(len(env.actions))\n",
    "    user_suggestions = []\n",
    "\n",
    "    for user_id in range(num_episodes):\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        step_count = 0  # Track steps per episode\n",
    "        actions_taken = []\n",
    "\n",
    "        while not done and step_count < max_steps: \n",
    "            action, _ = model.predict(state)\n",
    "            action_counts[action] += 1\n",
    "            actions_taken.append(env.actions[action])\n",
    "            state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            episode_reward += reward\n",
    "            step_count += 1\n",
    "\n",
    "        total_rewards.append(episode_reward)\n",
    "        user_suggestions.append((user_id + 1, actions_taken))\n",
    "\n",
    "    return np.mean(total_rewards), np.std(total_rewards), action_counts, user_suggestions\n",
    "\n",
    "\n",
    "# Load trained models\n",
    "dqn_model = DQN.load(\"mental_health_dqn_model\")\n",
    "a2c_model = A2C.load(\"mental_health_a2c_model\")\n",
    "\n",
    "# Evaluate both models\n",
    "dqn_mean, dqn_std, dqn_actions, dqn_suggestions = evaluate_model(dqn_model, env)\n",
    "a2c_mean, a2c_std, a2c_actions, a2c_suggestions = evaluate_model(a2c_model, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(24.59375)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.6302494318572656)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(33.2734375)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2c_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.109247406301684)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2c_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟢 A2C Model Suggestions:\n",
      "User 1: ['Watch educational videos']\n",
      "User 2: ['Watch educational videos']\n",
      "User 3: ['Watch educational videos']\n",
      "User 4: ['Watch educational videos']\n",
      "User 5: ['Watch educational videos']\n",
      "User 6: ['Watch educational videos']\n",
      "User 7: ['Watch educational videos']\n",
      "User 8: ['Watch educational videos']\n",
      "User 9: ['Watch educational videos']\n",
      "User 10: ['Watch educational videos']\n",
      "User 11: ['Watch educational videos']\n",
      "User 12: ['Watch educational videos']\n",
      "User 13: ['Watch educational videos']\n",
      "User 14: ['Watch educational videos']\n",
      "User 15: ['Watch educational videos']\n",
      "User 16: ['Watch educational videos']\n",
      "User 17: ['Watch educational videos']\n",
      "User 18: ['Watch educational videos']\n",
      "User 19: ['Watch educational videos']\n",
      "User 20: ['Watch educational videos']\n",
      "User 21: ['Watch educational videos']\n",
      "User 22: ['Watch educational videos']\n",
      "User 23: ['Watch educational videos']\n",
      "User 24: ['Watch educational videos']\n",
      "User 25: ['Watch educational videos']\n",
      "User 26: ['Watch educational videos']\n",
      "User 27: ['Watch educational videos']\n",
      "User 28: ['Watch educational videos']\n",
      "User 29: ['Watch educational videos']\n",
      "User 30: ['Watch educational videos']\n",
      "User 31: ['Watch educational videos']\n",
      "User 32: ['Watch educational videos']\n",
      "User 33: ['Watch educational videos']\n",
      "User 34: ['Watch educational videos']\n",
      "User 35: ['Watch educational videos']\n",
      "User 36: ['Watch educational videos']\n",
      "User 37: ['Watch educational videos']\n",
      "User 38: ['Watch educational videos']\n",
      "User 39: ['Watch educational videos']\n",
      "User 40: ['Watch educational videos']\n",
      "User 41: ['Watch educational videos']\n",
      "User 42: ['Watch educational videos']\n",
      "User 43: ['Interact with positive communities']\n",
      "User 44: ['Watch educational videos']\n",
      "User 45: ['Watch educational videos']\n",
      "User 46: ['Watch educational videos']\n",
      "User 47: ['Watch educational videos']\n",
      "User 48: ['Watch educational videos']\n",
      "User 49: ['Watch educational videos']\n",
      "User 50: ['Watch educational videos']\n",
      "User 51: ['Watch educational videos']\n",
      "User 52: ['Watch educational videos']\n",
      "User 53: ['Watch educational videos']\n",
      "User 54: ['Watch educational videos']\n",
      "User 55: ['Watch educational videos']\n",
      "User 56: ['Watch educational videos']\n",
      "User 57: ['Follow a structured daily routine']\n",
      "User 58: ['Watch educational videos']\n",
      "User 59: ['Watch educational videos']\n",
      "User 60: ['Watch educational videos']\n",
      "User 61: ['Watch educational videos']\n",
      "User 62: ['Watch educational videos']\n",
      "User 63: ['Watch educational videos']\n",
      "User 64: ['Watch educational videos']\n",
      "User 65: ['Watch educational videos']\n",
      "User 66: ['Watch educational videos']\n",
      "User 67: ['Watch educational videos']\n",
      "User 68: ['Watch educational videos']\n",
      "User 69: ['Watch educational videos']\n",
      "User 70: ['Watch educational videos']\n",
      "User 71: ['Watch educational videos']\n",
      "User 72: ['Watch educational videos']\n",
      "User 73: ['Watch educational videos']\n",
      "User 74: ['Watch educational videos']\n",
      "User 75: ['Watch educational videos']\n",
      "User 76: ['Follow a structured daily routine']\n",
      "User 77: ['Watch educational videos']\n",
      "User 78: ['Watch educational videos']\n",
      "User 79: ['Watch educational videos']\n",
      "User 80: ['Watch educational videos']\n",
      "User 81: ['Watch educational videos']\n",
      "User 82: ['Follow a structured daily routine']\n",
      "User 83: ['Watch educational videos']\n",
      "User 84: ['Watch educational videos']\n",
      "User 85: ['Watch educational videos']\n",
      "User 86: ['Watch educational videos']\n",
      "User 87: ['Watch educational videos']\n",
      "User 88: ['Watch educational videos']\n",
      "User 89: ['Follow a structured daily routine']\n",
      "User 90: ['Watch educational videos']\n",
      "User 91: ['Watch educational videos']\n",
      "User 92: ['Watch educational videos']\n",
      "User 93: ['Watch educational videos']\n",
      "User 94: ['Follow a structured daily routine']\n",
      "User 95: ['Watch educational videos']\n",
      "User 96: ['Watch educational videos']\n",
      "User 97: ['Watch educational videos']\n",
      "User 98: ['Watch educational videos']\n",
      "User 99: ['Watch educational videos']\n",
      "User 100: ['Watch educational videos']\n",
      "User 101: ['Watch educational videos']\n",
      "User 102: ['Watch educational videos']\n",
      "User 103: ['Watch educational videos']\n",
      "User 104: ['Watch educational videos']\n",
      "User 105: ['Watch educational videos']\n",
      "User 106: ['Watch educational videos']\n",
      "User 107: ['Watch educational videos']\n",
      "User 108: ['Follow a structured daily routine']\n",
      "User 109: ['Watch educational videos']\n",
      "User 110: ['Watch educational videos']\n",
      "User 111: ['Watch educational videos']\n",
      "User 112: ['Watch educational videos']\n",
      "User 113: ['Watch educational videos']\n",
      "User 114: ['Watch educational videos']\n",
      "User 115: ['Watch educational videos']\n",
      "User 116: ['Watch educational videos']\n",
      "User 117: ['Watch educational videos']\n",
      "User 118: ['Watch educational videos']\n",
      "User 119: ['Watch educational videos']\n",
      "User 120: ['Watch educational videos']\n",
      "User 121: ['Watch educational videos']\n",
      "User 122: ['Watch educational videos']\n",
      "User 123: ['Watch educational videos']\n",
      "User 124: ['Watch educational videos']\n",
      "User 125: ['Watch educational videos']\n",
      "User 126: ['Watch educational videos']\n",
      "User 127: ['Watch educational videos']\n",
      "User 128: ['Watch educational videos']\n"
     ]
    }
   ],
   "source": [
    "# print(\"\\n🔵 DQN Model Suggestions:\")\n",
    "# for user_id, actions in dqn_suggestions:\n",
    "#     print(f\"User {user_id}: {actions}\")\n",
    "\n",
    "print(\"\\n🟢 A2C Model Suggestions:\")\n",
    "for user_id, actions in a2c_suggestions:\n",
    "    print(f\"User {user_id}: {actions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MentalHealthEnv(gym.Env):\n",
    "    def __init__(self, df):\n",
    "        super(MentalHealthEnv, self).__init__()\n",
    "\n",
    "        self.df = df.copy().reset_index(drop=True)\n",
    "        self.current_index = 0\n",
    "\n",
    "        # Define observation space: 7 scores\n",
    "        self.observation_space = spaces.Box(low=0, high=300, shape=(7,), dtype=np.float32)\n",
    "\n",
    "        # Define discrete action space\n",
    "        self.actions = [\n",
    "            \"Engage in Outdoor activities\",\n",
    "            \"Reduce the social media usage\",\n",
    "            \"Watch educational videos\",\n",
    "            \"Increase mindfulness practicess like yoga\",\n",
    "            \"Interact with positive communities\",\n",
    "            \"Avoid stress-inducing content\",\n",
    "            \"Follow a structured daily routine\"\n",
    "        ]\n",
    "        self.action_space = spaces.Discrete(len(self.actions))\n",
    "\n",
    "        # Action effects\n",
    "        self.action_effects = {\n",
    "            \"Engage in Outdoor activities\": np.array([10, 5, 0, 8, -5, 7, 0]),\n",
    "            \"Reduce the social media usage\": np.array([5, -15, 0, 0, 10, 0, 0]),\n",
    "            \"Watch educational videos\": np.array([5, 0, 15, 7, -3, 10, 0]),\n",
    "            \"Increase mindfulness practicess like yoga\": np.array([12, 0, 0, 5, -8, 15, 0]),\n",
    "            \"Interact with positive communities\": np.array([8, 0, 0, 5, -5, 5, 0]),\n",
    "            \"Avoid stress-inducing content\": np.array([5, 0, 0, -10, 10, 5, 0]),\n",
    "            \"Follow a structured daily routine\": np.array([7, 0, 3, 6, -2, 8, 0])\n",
    "        }\n",
    "\n",
    "        self.state = self._get_state_from_row(self.current_index)\n",
    "\n",
    "    def _get_state_from_row(self, index):\n",
    "        return self.df.iloc[index, :7].values.astype(np.float32)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.current_index = np.random.randint(0, len(self.df))\n",
    "        self.state = self._get_state_from_row(self.current_index)\n",
    "        return self.state, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        action_str = self.actions[action]\n",
    "        effect = self.action_effects[action_str]\n",
    "\n",
    "        # Apply effect and clip\n",
    "        self.state = np.clip(self.state + effect, 0, 300)\n",
    "\n",
    "        # Reward can be based on improvements (e.g., sum of all scores)\n",
    "        reward = np.sum(effect)\n",
    "\n",
    "        # Simulate episode termination\n",
    "        done = False\n",
    "        if np.all(self.state >= 290):  # agent reached high scores\n",
    "            done = True\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        return self.state, reward, done, False, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
