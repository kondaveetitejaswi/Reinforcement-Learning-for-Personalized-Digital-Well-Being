{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shimmy\n",
      "  Using cached Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: gymnasium in c:\\users\\tejas\\anaconda3\\anaconda\\lib\\site-packages (1.0.0)\n",
      "Collecting gymnasium\n",
      "  Using cached gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\tejas\\anaconda3\\anaconda\\lib\\site-packages (from shimmy) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\tejas\\anaconda3\\anaconda\\lib\\site-packages (from gymnasium) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\tejas\\anaconda3\\anaconda\\lib\\site-packages (from gymnasium) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\tejas\\anaconda3\\anaconda\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Using cached Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
      "Using cached gymnasium-1.1.1-py3-none-any.whl (965 kB)\n",
      "Installing collected packages: gymnasium, shimmy\n",
      "  Attempting uninstall: gymnasium\n",
      "    Found existing installation: gymnasium 1.0.0\n",
      "    Uninstalling gymnasium-1.0.0:\n",
      "      Successfully uninstalled gymnasium-1.0.0\n",
      "Successfully installed gymnasium-1.1.1 shimmy-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "stable-baselines3 2.5.0 requires gymnasium<1.1.0,>=0.29.1, but you have gymnasium 1.1.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# pip install --upgrade shimmy gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from gym import spaces\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Mental_Health_Score_Dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotional_Score</th>\n",
       "      <th>Social_Media_Time_Score</th>\n",
       "      <th>Platform_Score</th>\n",
       "      <th>Usage_Pattern_Score</th>\n",
       "      <th>Impact_Score</th>\n",
       "      <th>Additional_Feature_Score</th>\n",
       "      <th>TFIDF_Score</th>\n",
       "      <th>Mental_Health_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>61</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotional_Score  Social_Media_Time_Score  Platform_Score  \\\n",
       "0               84                       13              20   \n",
       "1               56                       13              10   \n",
       "2               97                       23              19   \n",
       "3              114                       13              19   \n",
       "4               87                       13              19   \n",
       "\n",
       "   Usage_Pattern_Score  Impact_Score  Additional_Feature_Score  TFIDF_Score  \\\n",
       "0                   18            27                        38            0   \n",
       "1                    2             0                        35            0   \n",
       "2                   18            61                        34            0   \n",
       "3                   11            54                        63            0   \n",
       "4                   18            25                        10            0   \n",
       "\n",
       "   Mental_Health_Score  \n",
       "0                  200  \n",
       "1                  116  \n",
       "2                  252  \n",
       "3                  274  \n",
       "4                  172  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MentalHealthEnv(gym.Env):\n",
    "    def __init__(self, df):\n",
    "        super(MentalHealthEnv, self).__init__()\n",
    "\n",
    "        #loading the dataset\n",
    "        self.df = df.copy()\n",
    "        self.current_index = 0\n",
    "\n",
    "\n",
    "        #define state: 7 mental health scores (ranging between 0 to 300)\n",
    "        self.observation_space = spaces.Box(low = 0, high = 300, shape = (7,), dtype = np.float32)\n",
    "\n",
    "        # defining action space\n",
    "        self.actions = [\n",
    "            \"Engage in Outdoor activities\",\n",
    "            \"Reduce the social media usage\",\n",
    "            \"Watch educational videos\",\n",
    "            \"Increase mindfulness practicess like yoga\",\n",
    "            \"Interact with positive communities\",\n",
    "            \"Avoid stress-inducing content\",\n",
    "            \"Follow a structured daily routine\"\n",
    "        ]\n",
    "\n",
    "        self.action_space = spaces.Discrete(len(self.actions))\n",
    "\n",
    "        #initiating state: random values between 50 and 250 (to avoid zero-starting issues)\n",
    "        self.state = np.random.uniform(low = 50, high = 250, size = (7,))\n",
    "\n",
    "        # define action effects (each action affects specific scores)\n",
    "        self.action_effects = {\n",
    "            \"Engage in Outdoor activities\": np.array([10, 5, 0, 8, -5, 7, 0]),\n",
    "            \"Reduce the social media usage\": np.array([5, -15, 0, 0, 10, 0, 0]),\n",
    "            \"Watch educational videos\": np.array([5, 0, 15, 7, -3, 10, 0]),\n",
    "            \"Increase mindfulness practicess like yoga\": np.array([12, 0, 0, 5, -8, 15, 0]),\n",
    "            \"Interact with positive communities\": np.array([6, 0, -8, 0, 12, 0, 0]),\n",
    "            \"Avoid stress-inducing content\": np.array([6, 0, -8, 0, 12, 0, 0]),\n",
    "            \"Follow a structured daily routine\": np.array([10, 0, 0, 0, 7, 8, 0])\n",
    "        }\n",
    "        self.state = self.get_state_from_df()\n",
    "\n",
    "\n",
    "    def get_state_from_df(self):\n",
    "        # extract the initial state from the dataframe based on the current index\n",
    "        row = self.df.iloc[self.current_index]\n",
    "        return np.array(row[:-1])\n",
    "    \n",
    "    def step(self, action):\n",
    "        #apply an action and update mental health scores\n",
    "        self.state = np.clip(self.state + self.action_effects[self.actions[action]], 0, 300)\n",
    "\n",
    "\n",
    "        # reward: Improvement in mental health score \n",
    "        self.df.at[self.current_index, \"Mental_Health_Score\"] = np.sum(self.state)\n",
    "        reward = self.df.at[self.current_index, \"Mental_Health_Score\"]\n",
    "\n",
    "        #print(f\"State Shape: {self.state.shape}\")\n",
    "\n",
    "        done = np.all(self.state >= 280) #stops if all the score are near 300\n",
    "        \n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Move to the next user in the dataset or restart if finished.\"\"\"\n",
    "        self.current_index += 1  # Move to the next row\n",
    "        if self.current_index >= len(self.df):\n",
    "            self.current_index = 0  # Reset if all users are processed\n",
    "        self.state = self.get_state_from_df()\n",
    "        return self.state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MentalHealthEnv(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tejas\\anaconda3\\anaconda\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN, A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tejas\\anaconda3\\anaconda\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tejas\\anaconda3\\anaconda\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.23    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 5.62e+03 |\n",
      "|    value_loss         | 2.35e+07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.3     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 4.35e+03 |\n",
      "|    value_loss         | 2.39e+07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 358      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.07    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 2.04e+03 |\n",
      "|    value_loss         | 2.4e+07  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.786   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 2.97e+03 |\n",
      "|    value_loss         | 2.39e+07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1       |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 7.73e+03 |\n",
      "|    value_loss         | 2.4e+07  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.5     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 6.11e+03 |\n",
      "|    value_loss         | 2.57e+07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 353       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.82     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 1.11e+04  |\n",
      "|    value_loss         | 3.29e+07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 350      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.62    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 8.21e+03 |\n",
      "|    value_loss         | 3.41e+07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.64     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 8.32e+03  |\n",
      "|    value_loss         | 3.4e+07   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 350      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.51    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 6.96e+03 |\n",
      "|    value_loss         | 3.4e+07  |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dqn_model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "dqn_model.learn(total_timesteps=5000)\n",
    "dqn_model.save(\"mental_health_dqn_model\")\n",
    "\n",
    "# Train A2C\n",
    "a2c_model = A2C(\"MlpPolicy\", env, verbose=1)\n",
    "a2c_model.learn(total_timesteps=5000)\n",
    "a2c_model.save(\"mental_health_a2c_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, env, num_episodes=len(df), max_steps=1):\n",
    "    total_rewards = []\n",
    "    action_counts = np.zeros(len(env.actions))\n",
    "    user_suggestions = []\n",
    "\n",
    "    for user_id in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        step_count = 0  # Track steps per episode\n",
    "        actions_taken = []\n",
    "\n",
    "        while not done and step_count < max_steps: \n",
    "            action, _ = model.predict(state)\n",
    "            action_counts[action] += 1\n",
    "            actions_taken.append(env.actions[action])\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            episode_reward += reward\n",
    "            step_count += 1\n",
    "\n",
    "        total_rewards.append(episode_reward)\n",
    "        user_suggestions.append((user_id + 1, actions_taken))\n",
    "\n",
    "    return np.mean(total_rewards), np.std(total_rewards), action_counts, user_suggestions\n",
    "\n",
    "\n",
    "# Load trained models\n",
    "dqn_model = DQN.load(\"mental_health_dqn_model\")\n",
    "a2c_model = A2C.load(\"mental_health_a2c_model\")\n",
    "\n",
    "# Evaluate both models\n",
    "dqn_mean, dqn_std, dqn_actions, dqn_suggestions = evaluate_model(dqn_model, env)\n",
    "a2c_mean, a2c_std, a2c_actions, a2c_suggestions = evaluate_model(a2c_model, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231.703125"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.81028030962082"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231.859375"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2c_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.340777366608094"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2c_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔵 DQN Model Suggestions:\n",
      "User 1: ['Increase mindfulness practicess like yoga']\n",
      "User 2: ['Increase mindfulness practicess like yoga']\n",
      "User 3: ['Increase mindfulness practicess like yoga']\n",
      "User 4: ['Increase mindfulness practicess like yoga']\n",
      "User 5: ['Watch educational videos']\n",
      "User 6: ['Increase mindfulness practicess like yoga']\n",
      "User 7: ['Increase mindfulness practicess like yoga']\n",
      "User 8: ['Increase mindfulness practicess like yoga']\n",
      "User 9: ['Increase mindfulness practicess like yoga']\n",
      "User 10: ['Increase mindfulness practicess like yoga']\n",
      "User 11: ['Increase mindfulness practicess like yoga']\n",
      "User 12: ['Increase mindfulness practicess like yoga']\n",
      "User 13: ['Increase mindfulness practicess like yoga']\n",
      "User 14: ['Increase mindfulness practicess like yoga']\n",
      "User 15: ['Increase mindfulness practicess like yoga']\n",
      "User 16: ['Increase mindfulness practicess like yoga']\n",
      "User 17: ['Increase mindfulness practicess like yoga']\n",
      "User 18: ['Increase mindfulness practicess like yoga']\n",
      "User 19: ['Increase mindfulness practicess like yoga']\n",
      "User 20: ['Increase mindfulness practicess like yoga']\n",
      "User 21: ['Increase mindfulness practicess like yoga']\n",
      "User 22: ['Increase mindfulness practicess like yoga']\n",
      "User 23: ['Increase mindfulness practicess like yoga']\n",
      "User 24: ['Increase mindfulness practicess like yoga']\n",
      "User 25: ['Increase mindfulness practicess like yoga']\n",
      "User 26: ['Increase mindfulness practicess like yoga']\n",
      "User 27: ['Increase mindfulness practicess like yoga']\n",
      "User 28: ['Increase mindfulness practicess like yoga']\n",
      "User 29: ['Increase mindfulness practicess like yoga']\n",
      "User 30: ['Increase mindfulness practicess like yoga']\n",
      "User 31: ['Increase mindfulness practicess like yoga']\n",
      "User 32: ['Increase mindfulness practicess like yoga']\n",
      "User 33: ['Increase mindfulness practicess like yoga']\n",
      "User 34: ['Increase mindfulness practicess like yoga']\n",
      "User 35: ['Increase mindfulness practicess like yoga']\n",
      "User 36: ['Increase mindfulness practicess like yoga']\n",
      "User 37: ['Increase mindfulness practicess like yoga']\n",
      "User 38: ['Increase mindfulness practicess like yoga']\n",
      "User 39: ['Increase mindfulness practicess like yoga']\n",
      "User 40: ['Increase mindfulness practicess like yoga']\n",
      "User 41: ['Increase mindfulness practicess like yoga']\n",
      "User 42: ['Increase mindfulness practicess like yoga']\n",
      "User 43: ['Increase mindfulness practicess like yoga']\n",
      "User 44: ['Increase mindfulness practicess like yoga']\n",
      "User 45: ['Increase mindfulness practicess like yoga']\n",
      "User 46: ['Increase mindfulness practicess like yoga']\n",
      "User 47: ['Increase mindfulness practicess like yoga']\n",
      "User 48: ['Increase mindfulness practicess like yoga']\n",
      "User 49: ['Increase mindfulness practicess like yoga']\n",
      "User 50: ['Increase mindfulness practicess like yoga']\n",
      "User 51: ['Increase mindfulness practicess like yoga']\n",
      "User 52: ['Increase mindfulness practicess like yoga']\n",
      "User 53: ['Increase mindfulness practicess like yoga']\n",
      "User 54: ['Increase mindfulness practicess like yoga']\n",
      "User 55: ['Increase mindfulness practicess like yoga']\n",
      "User 56: ['Increase mindfulness practicess like yoga']\n",
      "User 57: ['Increase mindfulness practicess like yoga']\n",
      "User 58: ['Increase mindfulness practicess like yoga']\n",
      "User 59: ['Increase mindfulness practicess like yoga']\n",
      "User 60: ['Increase mindfulness practicess like yoga']\n",
      "User 61: ['Increase mindfulness practicess like yoga']\n",
      "User 62: ['Increase mindfulness practicess like yoga']\n",
      "User 63: ['Increase mindfulness practicess like yoga']\n",
      "User 64: ['Increase mindfulness practicess like yoga']\n",
      "User 65: ['Increase mindfulness practicess like yoga']\n",
      "User 66: ['Increase mindfulness practicess like yoga']\n",
      "User 67: ['Increase mindfulness practicess like yoga']\n",
      "User 68: ['Increase mindfulness practicess like yoga']\n",
      "User 69: ['Increase mindfulness practicess like yoga']\n",
      "User 70: ['Increase mindfulness practicess like yoga']\n",
      "User 71: ['Increase mindfulness practicess like yoga']\n",
      "User 72: ['Increase mindfulness practicess like yoga']\n",
      "User 73: ['Increase mindfulness practicess like yoga']\n",
      "User 74: ['Increase mindfulness practicess like yoga']\n",
      "User 75: ['Increase mindfulness practicess like yoga']\n",
      "User 76: ['Increase mindfulness practicess like yoga']\n",
      "User 77: ['Increase mindfulness practicess like yoga']\n",
      "User 78: ['Increase mindfulness practicess like yoga']\n",
      "User 79: ['Increase mindfulness practicess like yoga']\n",
      "User 80: ['Increase mindfulness practicess like yoga']\n",
      "User 81: ['Increase mindfulness practicess like yoga']\n",
      "User 82: ['Increase mindfulness practicess like yoga']\n",
      "User 83: ['Increase mindfulness practicess like yoga']\n",
      "User 84: ['Increase mindfulness practicess like yoga']\n",
      "User 85: ['Increase mindfulness practicess like yoga']\n",
      "User 86: ['Increase mindfulness practicess like yoga']\n",
      "User 87: ['Increase mindfulness practicess like yoga']\n",
      "User 88: ['Increase mindfulness practicess like yoga']\n",
      "User 89: ['Increase mindfulness practicess like yoga']\n",
      "User 90: ['Increase mindfulness practicess like yoga']\n",
      "User 91: ['Increase mindfulness practicess like yoga']\n",
      "User 92: ['Increase mindfulness practicess like yoga']\n",
      "User 93: ['Increase mindfulness practicess like yoga']\n",
      "User 94: ['Increase mindfulness practicess like yoga']\n",
      "User 95: ['Increase mindfulness practicess like yoga']\n",
      "User 96: ['Increase mindfulness practicess like yoga']\n",
      "User 97: ['Increase mindfulness practicess like yoga']\n",
      "User 98: ['Increase mindfulness practicess like yoga']\n",
      "User 99: ['Increase mindfulness practicess like yoga']\n",
      "User 100: ['Increase mindfulness practicess like yoga']\n",
      "User 101: ['Increase mindfulness practicess like yoga']\n",
      "User 102: ['Increase mindfulness practicess like yoga']\n",
      "User 103: ['Increase mindfulness practicess like yoga']\n",
      "User 104: ['Increase mindfulness practicess like yoga']\n",
      "User 105: ['Increase mindfulness practicess like yoga']\n",
      "User 106: ['Increase mindfulness practicess like yoga']\n",
      "User 107: ['Increase mindfulness practicess like yoga']\n",
      "User 108: ['Increase mindfulness practicess like yoga']\n",
      "User 109: ['Increase mindfulness practicess like yoga']\n",
      "User 110: ['Increase mindfulness practicess like yoga']\n",
      "User 111: ['Increase mindfulness practicess like yoga']\n",
      "User 112: ['Increase mindfulness practicess like yoga']\n",
      "User 113: ['Increase mindfulness practicess like yoga']\n",
      "User 114: ['Increase mindfulness practicess like yoga']\n",
      "User 115: ['Increase mindfulness practicess like yoga']\n",
      "User 116: ['Increase mindfulness practicess like yoga']\n",
      "User 117: ['Increase mindfulness practicess like yoga']\n",
      "User 118: ['Increase mindfulness practicess like yoga']\n",
      "User 119: ['Increase mindfulness practicess like yoga']\n",
      "User 120: ['Increase mindfulness practicess like yoga']\n",
      "User 121: ['Increase mindfulness practicess like yoga']\n",
      "User 122: ['Increase mindfulness practicess like yoga']\n",
      "User 123: ['Increase mindfulness practicess like yoga']\n",
      "User 124: ['Increase mindfulness practicess like yoga']\n",
      "User 125: ['Increase mindfulness practicess like yoga']\n",
      "User 126: ['Increase mindfulness practicess like yoga']\n",
      "User 127: ['Increase mindfulness practicess like yoga']\n",
      "User 128: ['Increase mindfulness practicess like yoga']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🔵 DQN Model Suggestions:\")\n",
    "for user_id, actions in dqn_suggestions:\n",
    "    print(f\"User {user_id}: {actions}\")\n",
    "\n",
    "# print(\"\\n🟢 A2C Model Suggestions:\")\n",
    "# for user_id, actions in a2c_suggestions:\n",
    "#     print(f\"User {user_id}: {actions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
