{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shimmy in c:\\users\\tejas\\anaconda3\\anaconda\\envs\\pytorch_env\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: gymnasium in c:\\users\\tejas\\anaconda3\\anaconda\\envs\\pytorch_env\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\tejas\\anaconda3\\anaconda\\envs\\pytorch_env\\lib\\site-packages (from shimmy) (2.2.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\tejas\\anaconda3\\anaconda\\envs\\pytorch_env\\lib\\site-packages (from gymnasium) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\tejas\\anaconda3\\anaconda\\envs\\pytorch_env\\lib\\site-packages (from gymnasium) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\tejas\\anaconda3\\anaconda\\envs\\pytorch_env\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install --upgrade shimmy gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from gym import spaces\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Mental_Health_Score_Dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotional_Score</th>\n",
       "      <th>Social_Media_Time_Score</th>\n",
       "      <th>Platform_Score</th>\n",
       "      <th>Usage_Pattern_Score</th>\n",
       "      <th>Impact_Score</th>\n",
       "      <th>Additional_Feature_Score</th>\n",
       "      <th>TFIDF_Score</th>\n",
       "      <th>Mental_Health_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>61</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotional_Score  Social_Media_Time_Score  Platform_Score  \\\n",
       "0               84                       13              20   \n",
       "1               56                       13              10   \n",
       "2               97                       23              19   \n",
       "3              114                       13              19   \n",
       "4               87                       13              19   \n",
       "\n",
       "   Usage_Pattern_Score  Impact_Score  Additional_Feature_Score  TFIDF_Score  \\\n",
       "0                   18            27                        38            0   \n",
       "1                    2             0                        35            0   \n",
       "2                   18            61                        34            0   \n",
       "3                   11            54                        63            0   \n",
       "4                   18            25                        10            0   \n",
       "\n",
       "   Mental_Health_Score  \n",
       "0                  200  \n",
       "1                  116  \n",
       "2                  252  \n",
       "3                  274  \n",
       "4                  172  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MentalHealthEnv(gym.Env):\n",
    "    def __init__(self, df):\n",
    "        super(MentalHealthEnv, self).__init__()\n",
    "\n",
    "        #loading the dataset\n",
    "        self.df = df.copy()\n",
    "        self.current_index = 0\n",
    "\n",
    "\n",
    "        #define state: 7 mental health scores (ranging between 0 to 300)\n",
    "        self.observation_space = spaces.Box(low = 0, high = 300, shape = (7,), dtype = np.float32)\n",
    "\n",
    "        # defining action space\n",
    "        self.actions = [\n",
    "            \"Engage in Outdoor activities\",\n",
    "            \"Reduce the social media usage\",\n",
    "            \"Watch educational videos\",\n",
    "            \"Increase mindfulness practicess like yoga\",\n",
    "            \"Interact with positive communities\",\n",
    "            \"Avoid stress-inducing content\",\n",
    "            \"Follow a structured daily routine\"\n",
    "        ]\n",
    "\n",
    "        self.action_space = spaces.Discrete(len(self.actions))\n",
    "\n",
    "        #initiating state: random values between 50 and 250 (to avoid zero-starting issues)\n",
    "        self.state = np.random.uniform(low = 50, high = 250, size = (7,))\n",
    "\n",
    "        # define action effects (each action affects specific scores)\n",
    "        self.action_effects = {\n",
    "            \"Engage in Outdoor activities\": np.array([10, 5, 0, 8, -5, 7, 0]),\n",
    "            \"Reduce the social media usage\": np.array([5, -15, 0, 0, 10, 0, 0]),\n",
    "            \"Watch educational videos\": np.array([5, 0, 15, 7, -3, 10, 0]),\n",
    "            \"Increase mindfulness practicess like yoga\": np.array([12, 0, 0, 5, -8, 15, 0]),\n",
    "            \"Interact with positive communities\": np.array([6, 0, -8, 0, 12, 0, 0]),\n",
    "            \"Avoid stress-inducing content\": np.array([6, 0, -8, 0, 12, 0, 0]),\n",
    "            \"Follow a structured daily routine\": np.array([10, 0, 0, 0, 7, 8, 0])\n",
    "        }\n",
    "        self.state = self.get_state_from_df()\n",
    "\n",
    "\n",
    "    def get_state_from_df(self):\n",
    "        # extract the initial state from the dataframe based on the current index\n",
    "        row = self.df.iloc[self.current_index]\n",
    "        return np.array(row[:-1])\n",
    "    \n",
    "    def step(self, action):\n",
    "        #apply an action and update mental health scores\n",
    "        self.state = np.clip(self.state + self.action_effects[self.actions[action]], 0, 300)\n",
    "\n",
    "\n",
    "        # reward: Improvement in mental health score \n",
    "        self.df.at[self.current_index, \"Mental_Health_Score\"] = np.sum(self.state)\n",
    "        reward = self.df.at[self.current_index, \"Mental_Health_Score\"]\n",
    "\n",
    "        #print(f\"State Shape: {self.state.shape}\")\n",
    "\n",
    "        done = np.all(self.state >= 280) #stops if all the score are near 300\n",
    "        \n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Move to the next user in the dataset or restart if finished.\"\"\"\n",
    "        self.current_index += 1  # Move to the next row\n",
    "        if self.current_index >= len(self.df):\n",
    "            self.current_index = 0  # Reset if all users are processed\n",
    "        self.state = self.get_state_from_df()\n",
    "        return self.state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MentalHealthEnv(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN, A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tejas\\anaconda3\\anaconda\\envs\\pytorch_env\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tejas\\anaconda3\\anaconda\\envs\\pytorch_env\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 309       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.9      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 6.44e+03  |\n",
      "|    value_loss         | 1.56e+07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 309      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.9     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 6.51e+03 |\n",
      "|    value_loss         | 1.55e+07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 303      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.91    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 7.23e+03 |\n",
      "|    value_loss         | 1.54e+07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.89     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 6.66e+03  |\n",
      "|    value_loss         | 1.53e+07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.78    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 5.11e+03 |\n",
      "|    value_loss         | 1.53e+07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 322      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.73    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 4.92e+03 |\n",
      "|    value_loss         | 1.53e+07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 326       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.65     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 5.5e+03   |\n",
      "|    value_loss         | 1.53e+07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.79    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 7.24e+03 |\n",
      "|    value_loss         | 2.31e+07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.74     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 7.62e+03  |\n",
      "|    value_loss         | 2.32e+07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.7     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 5.57e+03 |\n",
      "|    value_loss         | 2.39e+07 |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dqn_model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "dqn_model.learn(total_timesteps=5000)\n",
    "dqn_model.save(\"mental_health_dqn_model\")\n",
    "\n",
    "# Train A2C\n",
    "a2c_model = A2C(\"MlpPolicy\", env, verbose=1)\n",
    "a2c_model.learn(total_timesteps=5000)\n",
    "a2c_model.save(\"mental_health_a2c_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, env, num_episodes=10, max_steps=100):\n",
    "    total_rewards = []\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        step_count = 0  # Track steps per episode\n",
    "\n",
    "        while not done and step_count < max_steps: \n",
    "            action, _ = model.predict(state)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            episode_reward += reward\n",
    "            step_count += 1\n",
    "\n",
    "        total_rewards.append(episode_reward)\n",
    "\n",
    "    return np.mean(total_rewards), np.std(total_rewards)\n",
    "\n",
    "\n",
    "# Load trained models\n",
    "dqn_model = DQN.load(\"mental_health_dqn_model\")\n",
    "a2c_model = A2C.load(\"mental_health_a2c_model\")\n",
    "\n",
    "# Evaluate both models\n",
    "dqn_mean, dqn_std = evaluate_model(dqn_model, env)\n",
    "a2c_mean, a2c_std = evaluate_model(a2c_model, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(84305.2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2201.599227834167)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(101014.2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2c_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7506.765732324408)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2c_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
